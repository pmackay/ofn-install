--- # Backup

#--------------------
# Get timestamp

- name: get current date for timestamp
  shell: date +"%Y-%m-%d-%I%M%S"
  register: current_date
  tags: backup

#-----------------
# Backup and fetch
# @TODO cleanup old backups

# Create a new database backup every time
- name: backup remote database
  shell: pg_dump -h {{ db_host }} -U {{ db_user }} {{ db }} | gzip > {{ backup_path }}/{{ backup_filename }}
  become: yes
  become_user: "{{ unicorn_user }}"

- name: fetch database to local
  fetch:
    src: "{{ backup_path }}/{{ backup_filename }}"
    dest: "{{ local_backup_path }}/{{ domain }}/databases/"
    fail_on_missing: yes
    flat: yes

# But we don't bother making a whole new copy of all the files every time, just rsync them.
- name: sync public files to local
  synchronize:
    mode: pull
    src: "{{ current_path }}/public"
    dest: "{{ local_rsync_path }}/{{ domain }}/files"
    copy_links: yes
  tags: rsync

# @TODO just delete anything older than the newest {{ num_remote_backups }} files
#- name: Get number of backups
  #shell: ls | grep ".sql.gz" | wc -w
  #register: num_backups

#- name: Delete old backups
  #shell: rm
  #when: num_backups.stdout > {{ num_remote_backups }}
